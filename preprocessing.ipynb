{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1ff20c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "import json\n",
    "import spacy\n",
    "nlp = spacy.load('nl_core_news_sm')\n",
    "from nltk import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "165c631e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/volume_2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dd625207",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selecttxt(article):\n",
    "    text = ''\n",
    "    try:\n",
    "        text = text + ' ' + article['text']\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        text = text + ' ' + article['byline']\n",
    "    except:\n",
    "        pass\n",
    "    try: #in case of title there is often a \"VOLLEDIGE TEKST\" part\n",
    "        text = text + ' ' + article['title']\n",
    "    except:\n",
    "        pass \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "01c4b9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sentences):\n",
    "    words = []\n",
    "    for sentence in sentences:            \n",
    "        newsent = []\n",
    "        newwords = nlp(sentence)\n",
    "        for token in newwords:\n",
    "            newsent.append(str(token))\n",
    "        newsentence = ' '.join(newsent).lower()\n",
    "        #print('newsentence type =', type(newsentence))\n",
    "        words.append(newsentence) \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0c6f63a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_file(outfile, tokens):\n",
    "    with open(outfile, 'a', encoding='utf-8') as newfile:\n",
    "        for sentence in tokens:\n",
    "            ssentence = sentence + '\\n'\n",
    "            newfile.write(ssentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9dc994ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_all(krant): \n",
    "    print('working on...')\n",
    "    print(krant)\n",
    "    infile = krant + ' (print).json'\n",
    "    f = open(infile, 'r', encoding='utf-8') #changed: encoding='utf-8'\n",
    "    print('file opened')\n",
    "\n",
    "    counter = 0\n",
    "\n",
    "\n",
    "    for line in f:\n",
    "        article = json.loads(line)\n",
    "        date = article[\"publication_date\"]\n",
    "        year = int(date[:4])\n",
    "        if year > 2009:\n",
    "            counter += 1\n",
    "            outfile1 = 'lowercased/' + krant + '.txt'\n",
    "            month = int(date[5:7])\n",
    "            if month < 7:\n",
    "                outfile2 = 'lowercased/' + str(year) + '_1.txt'\n",
    "                outfile3 = 'lowercased/' + str(year-1) + '_2.txt'\n",
    "            else:\n",
    "                outfile2 = 'lowercased/' + str(year) + '_1.txt'\n",
    "                outfile3 = 'lowercased/' + str(year) + '_2.txt'\n",
    "            text = selecttxt(article)\n",
    "            sentences = sent_tokenize(text, language=\"dutch\")\n",
    "            if text != '':\n",
    "                tokens = tokenize(sentences) #list of strings per sentence\n",
    "                write_file(outfile1, tokens)\n",
    "                write_file(outfile2, tokens)\n",
    "                write_file(outfile3, tokens)\n",
    "                if counter % 5000 == 0:\n",
    "                    print(str(counter) + \"/334808\")\n",
    "            else:\n",
    "                nnotext += 1\n",
    "\n",
    "    print('finished')\n",
    "\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4a0d82",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on...\n",
      "ad\n",
      "file opened\n",
      "5000/334808\n",
      "10000/334808\n"
     ]
    }
   ],
   "source": [
    "preprocess_all('ad')\n",
    "print('AD preprocessed')\n",
    "preprocess_all('nrc')\n",
    "print('NRC preprocessed')\n",
    "preprocess_all('telegraaf')\n",
    "print('telegraaf preprocessed')\n",
    "preprocess_all('trouw')\n",
    "print('trouw preprocessed')\n",
    "preprocess_all('volkskrant')\n",
    "print('vk preprocessed')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "972cae3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "currently working on ad\n",
      "currently working on 2010\n",
      "currently working on 2011\n",
      "currently working on 2012\n",
      "currently working on 2013\n",
      "currently working on 2014\n",
      "currently working on 2015\n",
      "currently working on 2016\n",
      "currently working on 2017\n",
      "currently working on 2018\n",
      "currently working on nrc\n",
      "currently working on 2010\n",
      "currently working on 2011\n",
      "currently working on 2012\n",
      "currently working on 2013\n",
      "currently working on 2014\n",
      "currently working on 2015\n",
      "currently working on 2016\n",
      "currently working on 2017\n",
      "currently working on 2018\n",
      "currently working on telegraaf\n",
      "currently working on 2010\n",
      "currently working on 2011\n",
      "currently working on 2012\n",
      "currently working on 2013\n",
      "currently working on 2014\n",
      "currently working on 2015\n",
      "currently working on 2016\n",
      "currently working on 2017\n",
      "currently working on 2018\n",
      "currently working on trouw\n",
      "currently working on 2010\n",
      "currently working on 2011\n",
      "currently working on 2012\n",
      "currently working on 2013\n",
      "currently working on 2014\n",
      "currently working on 2015\n",
      "currently working on 2016\n",
      "currently working on 2017\n",
      "currently working on 2018\n",
      "currently working on volkskrant\n",
      "currently working on 2010\n",
      "currently working on 2011\n",
      "currently working on 2012\n",
      "currently working on 2013\n",
      "currently working on 2014\n",
      "currently working on 2015\n",
      "currently working on 2016\n",
      "currently working on 2017\n",
      "currently working on 2018\n"
     ]
    }
   ],
   "source": [
    "papers = ['ad', 'nrc', 'telegraaf', 'trouw', 'volkskrant']\n",
    "years = ['2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018']\n",
    "\n",
    "\n",
    "\n",
    "for p in papers:\n",
    "    print('currently working on ' + p)\n",
    "    for y in years:\n",
    "        print('currently working on ' + y)\n",
    "        filename = p + y + 'unicode.txt'\n",
    "        with open(filename, encoding='utf-8') as file:\n",
    "            newfile = file.readlines()\n",
    "        for line in newfile:\n",
    "            with open('lowercased/compass.txt', 'a', encoding='utf-8') as outfile:\n",
    "                outfile.write(line.lower()) #was outfile.write(line)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd72a628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['   topdag el hamdaoui\\n', '   eerste zege fc twente\\n', \"   münchen - de man die de duitse taal verrijkte met nieuwe woorden als   ' löfeltje , löfeltje ' heeft in duitsland een taalprijs gewonnen .\\n\", \"louis van gaal , trainer van topclub bayern münchen , werd verkozen tot ' die sprachwahrer des jahres 2009 ' vanwege zijn ' voorbeeldige inzet ' voor de duitse taal .\\n\", 'de prijs wordt jaarlijks toegekend door die deutsche sprachwelt ( dsw ) , een tijdschrift over de duitse taal .\\n', 'voordat van gaal vorig jaar zomer in beieren aan de slag ging volgde hij een week lang een intensieve cursus duits .\\n', \"bovendien viel bij het tijdschrift in de smaak dat hij van niet-duitse spelers verwacht dat ze in ' no-time ' de taal beheersen .\\n\", 'beroemd in duitsland is het zinnetje dat van gaal uitsprak bij zijn presentatie bij bayern in juli .\\n', ',, wer in deutschland spielt , muß sich der kultur anpassen .\\n', \"dazu gehört die sprache . ''\\n\"]\n"
     ]
    }
   ],
   "source": [
    "with open('lowercased/compass.txt') as file:\n",
    "    doc = file.readlines()\n",
    "    \n",
    "print(doc[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f52f5a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
